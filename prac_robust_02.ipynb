{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "## Data Load\n",
    "train_df = pd.read_csv('./Data/train.csv') # Train\n",
    "train_df.head()\n",
    "val_df = pd.read_csv('./Data/val.csv') # Validation\n",
    "val_df.head()\n",
    "\n",
    "val_normal, val_fraud = val_df['Class'].value_counts()\n",
    "val_contamination = val_fraud / val_normal\n",
    "train_x = train_df.drop(columns=['ID']) # Input Data\n",
    "def get_pred_label(model_pred):\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred\n",
    "val_x = val_df.drop(columns=['ID', 'Class']) # Input Data\n",
    "val_y = val_df['Class'] # Label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from matplotlib import ticker, cm\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 31)\n",
      "Index(['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dfRaw = pd.read_csv('./Data/train.csv')\n",
    "print(dfRaw.shape)\n",
    "print(dfRaw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x2 = val_x[:]\n",
    "val_x2.drop(['V29','V28'],axis=1,inplace=True)\n",
    "# val_x2.drop(['V29','V28','V19','V13','V15'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(val_df.columns)[1:31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col3set = []\n",
    "for col1 in colnames:\n",
    "    for col2 in colnames:\n",
    "        for col3 in colnames:\n",
    "            if([col1,col2,col3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V1', 'V1'] F1 score on Test 0.7458\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V1', 'V2'] F1 score on Test 0.4746\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V1', 'V3'] F1 score on Test 0.1695\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V1', 'V4'] F1 score on Test 0.339\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V1', 'V5'] F1 score on Test 0.678\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V1', 'V6'] F1 score on Test 0.4068\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V1', 'V7'] F1 score on Test 0.4746\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V1', 'V8'] F1 score on Test 0.7458\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V1', 'V9'] F1 score on Test 0.4068\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V1', 'V10'] F1 score on Test 0.339\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V1', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V1', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.7931 recall  0.7667\n",
      "drop colnames ['V1', 'V13'] F1 score on Test 0.7797\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V1', 'V14'] F1 score on Test 0.339\n",
      "precision  0.6552 recall  0.6333\n",
      "drop colnames ['V1', 'V15'] F1 score on Test 0.6441\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V1', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V1', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V1', 'V18'] F1 score on Test 0.1017\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V1', 'V19'] F1 score on Test 0.339\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V1', 'V20'] F1 score on Test 0.5424\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V1', 'V21'] F1 score on Test 0.8136\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V1', 'V22'] F1 score on Test 0.8136\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V1', 'V23'] F1 score on Test 0.5424\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V1', 'V24'] F1 score on Test 0.5424\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V1', 'V25'] F1 score on Test 0.4746\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V1', 'V26'] F1 score on Test 0.678\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V1', 'V27'] F1 score on Test 0.5424\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V1', 'V28'] F1 score on Test 0.5424\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V1', 'V29'] F1 score on Test 0.4746\n",
      "precision  0.6552 recall  0.6333\n",
      "drop colnames ['V1', 'V30'] F1 score on Test 0.6441\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V2', 'V1'] F1 score on Test 0.4746\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V2'] F1 score on Test 0.8136\n",
      "precision  0.2414 recall  0.2333\n",
      "drop colnames ['V2', 'V3'] F1 score on Test 0.2373\n",
      "precision  0.2414 recall  0.2333\n",
      "drop colnames ['V2', 'V4'] F1 score on Test 0.2373\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V2', 'V5'] F1 score on Test 0.4068\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V2', 'V6'] F1 score on Test 0.8475\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V2', 'V7'] F1 score on Test 0.4746\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V2', 'V8'] F1 score on Test 0.8475\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V2', 'V9'] F1 score on Test 0.4068\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V2', 'V10'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V2', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V2', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V13'] F1 score on Test 0.8136\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V2', 'V14'] F1 score on Test 0.3729\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V15'] F1 score on Test 0.8136\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V2', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V2', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V2', 'V18'] F1 score on Test 0.1695\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V2', 'V19'] F1 score on Test 0.4746\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V2', 'V20'] F1 score on Test 0.7458\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V2', 'V21'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V2', 'V22'] F1 score on Test 0.8475\n",
      "precision  0.5862 recall  0.5667\n",
      "drop colnames ['V2', 'V23'] F1 score on Test 0.5763\n",
      "precision  0.7931 recall  0.7667\n",
      "drop colnames ['V2', 'V24'] F1 score on Test 0.7797\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V25'] F1 score on Test 0.8136\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V26'] F1 score on Test 0.8136\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V2', 'V27'] F1 score on Test 0.678\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V2', 'V28'] F1 score on Test 0.678\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V2', 'V29'] F1 score on Test 0.4746\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V2', 'V30'] F1 score on Test 0.8136\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V1'] F1 score on Test 0.1695\n",
      "precision  0.2414 recall  0.2333\n",
      "drop colnames ['V3', 'V2'] F1 score on Test 0.2373\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V3', 'V3'] F1 score on Test 0.5424\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V3', 'V4'] F1 score on Test 0.4407\n",
      "precision  0.2759 recall  0.2667\n",
      "drop colnames ['V3', 'V5'] F1 score on Test 0.2712\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V6'] F1 score on Test 0.1695\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V3', 'V7'] F1 score on Test 0.3729\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V3', 'V8'] F1 score on Test 0.5424\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V3', 'V9'] F1 score on Test 0.4407\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V3', 'V10'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V3', 'V13'] F1 score on Test 0.5424\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V14'] F1 score on Test 0.1695\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V3', 'V15'] F1 score on Test 0.4746\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V3', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V3', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V3', 'V18'] F1 score on Test 0.0678\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V3', 'V19'] F1 score on Test 0.339\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V3', 'V20'] F1 score on Test 0.4407\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V3', 'V21'] F1 score on Test 0.678\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V3', 'V22'] F1 score on Test 0.5424\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V3', 'V23'] F1 score on Test 0.3729\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V3', 'V24'] F1 score on Test 0.4407\n",
      "precision  0.2069 recall  0.2\n",
      "drop colnames ['V3', 'V25'] F1 score on Test 0.2034\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V3', 'V26'] F1 score on Test 0.4746\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V3', 'V27'] F1 score on Test 0.4068\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V3', 'V28'] F1 score on Test 0.4407\n",
      "precision  0.2759 recall  0.2667\n",
      "drop colnames ['V3', 'V29'] F1 score on Test 0.2712\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V3', 'V30'] F1 score on Test 0.4746\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V4', 'V1'] F1 score on Test 0.339\n",
      "precision  0.2414 recall  0.2333\n",
      "drop colnames ['V4', 'V2'] F1 score on Test 0.2373\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V3'] F1 score on Test 0.4407\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V4'] F1 score on Test 0.4407\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V4', 'V5'] F1 score on Test 0.0678\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V4', 'V6'] F1 score on Test 0.339\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V4', 'V7'] F1 score on Test 0.339\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V4', 'V8'] F1 score on Test 0.5424\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V9'] F1 score on Test 0.4407\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V4', 'V10'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V4', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V4', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.5172 recall  0.5\n",
      "drop colnames ['V4', 'V13'] F1 score on Test 0.5085\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V4', 'V14'] F1 score on Test 0.1695\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V15'] F1 score on Test 0.4407\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V4', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V4', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V4', 'V18'] F1 score on Test 0.1017\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V4', 'V19'] F1 score on Test 0.1695\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V20'] F1 score on Test 0.4407\n",
      "precision  0.6207 recall  0.6\n",
      "drop colnames ['V4', 'V21'] F1 score on Test 0.6102\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V4', 'V22'] F1 score on Test 0.5424\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V4', 'V23'] F1 score on Test 0.339\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V24'] F1 score on Test 0.4407\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V4', 'V25'] F1 score on Test 0.339\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V4', 'V26'] F1 score on Test 0.0678\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V4', 'V27'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V4', 'V28'] F1 score on Test 0.3729\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V4', 'V29'] F1 score on Test 0.0678\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V4', 'V30'] F1 score on Test 0.4407\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V5', 'V1'] F1 score on Test 0.678\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V5', 'V2'] F1 score on Test 0.4068\n",
      "precision  0.2759 recall  0.2667\n",
      "drop colnames ['V5', 'V3'] F1 score on Test 0.2712\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V5', 'V4'] F1 score on Test 0.0678\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V5', 'V5'] F1 score on Test 0.7458\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V5', 'V6'] F1 score on Test 0.4407\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V5', 'V7'] F1 score on Test 0.4068\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V5', 'V8'] F1 score on Test 0.7458\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V5', 'V9'] F1 score on Test 0.4407\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V5', 'V10'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V5', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V5', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V5', 'V13'] F1 score on Test 0.7458\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V5', 'V14'] F1 score on Test 0.339\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V5', 'V15'] F1 score on Test 0.4746\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V5', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V5', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V5', 'V18'] F1 score on Test 0.1017\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V5', 'V19'] F1 score on Test 0.339\n",
      "precision  0.6207 recall  0.6\n",
      "drop colnames ['V5', 'V20'] F1 score on Test 0.6102\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V5', 'V21'] F1 score on Test 0.8136\n",
      "precision  0.7931 recall  0.7667\n",
      "drop colnames ['V5', 'V22'] F1 score on Test 0.7797\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V5', 'V23'] F1 score on Test 0.4746\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V5', 'V24'] F1 score on Test 0.5424\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V5', 'V25'] F1 score on Test 0.4746\n",
      "precision  0.5862 recall  0.5667\n",
      "drop colnames ['V5', 'V26'] F1 score on Test 0.5763\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V5', 'V27'] F1 score on Test 0.4746\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V5', 'V28'] F1 score on Test 0.5424\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V5', 'V29'] F1 score on Test 0.339\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V5', 'V30'] F1 score on Test 0.678\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V6', 'V1'] F1 score on Test 0.3729\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V2'] F1 score on Test 0.8475\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V6', 'V3'] F1 score on Test 0.1695\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V6', 'V4'] F1 score on Test 0.339\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V6', 'V5'] F1 score on Test 0.4407\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V6'] F1 score on Test 0.8475\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V6', 'V7'] F1 score on Test 0.7458\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V8'] F1 score on Test 0.8475\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V6', 'V9'] F1 score on Test 0.4407\n",
      "precision  0.2759 recall  0.2667\n",
      "drop colnames ['V6', 'V10'] F1 score on Test 0.2712\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V6', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V6', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V13'] F1 score on Test 0.8475\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V6', 'V14'] F1 score on Test 0.1695\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V15'] F1 score on Test 0.8475\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V6', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V6', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V6', 'V18'] F1 score on Test 0.1017\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V6', 'V19'] F1 score on Test 0.4407\n",
      "precision  0.6552 recall  0.6333\n",
      "drop colnames ['V6', 'V20'] F1 score on Test 0.6441\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V21'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V22'] F1 score on Test 0.8475\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V6', 'V23'] F1 score on Test 0.7458\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V6', 'V24'] F1 score on Test 0.7458\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V6', 'V25'] F1 score on Test 0.8475\n",
      "precision  0.7931 recall  0.7667\n",
      "drop colnames ['V6', 'V26'] F1 score on Test 0.7797\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V6', 'V27'] F1 score on Test 0.7458\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V6', 'V28'] F1 score on Test 0.678\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V6', 'V29'] F1 score on Test 0.678\n",
      "precision  0.8276 recall  0.8\n",
      "drop colnames ['V6', 'V30'] F1 score on Test 0.8136\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V7', 'V1'] F1 score on Test 0.4746\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V7', 'V2'] F1 score on Test 0.4746\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V7', 'V3'] F1 score on Test 0.3729\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V7', 'V4'] F1 score on Test 0.339\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V7', 'V5'] F1 score on Test 0.4068\n",
      "precision  0.7241 recall  0.7\n",
      "drop colnames ['V7', 'V6'] F1 score on Test 0.7119\n",
      "precision  0.6552 recall  0.6333\n",
      "drop colnames ['V7', 'V7'] F1 score on Test 0.6441\n",
      "precision  0.7241 recall  0.7\n",
      "drop colnames ['V7', 'V8'] F1 score on Test 0.7119\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V7', 'V9'] F1 score on Test 0.4068\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V7', 'V10'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V7', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V7', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V13'] F1 score on Test 0.5424\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V7', 'V14'] F1 score on Test 0.3729\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V15'] F1 score on Test 0.5424\n",
      "precision  0.2414 recall  0.2333\n",
      "drop colnames ['V7', 'V16'] F1 score on Test 0.2373\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V7', 'V17'] F1 score on Test 0.1695\n",
      "precision  0.3103 recall  0.3\n",
      "drop colnames ['V7', 'V18'] F1 score on Test 0.3051\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V19'] F1 score on Test 0.5424\n",
      "precision  0.5862 recall  0.5667\n",
      "drop colnames ['V7', 'V20'] F1 score on Test 0.5763\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V7', 'V21'] F1 score on Test 0.678\n",
      "precision  0.5862 recall  0.5667\n",
      "drop colnames ['V7', 'V22'] F1 score on Test 0.5763\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V7', 'V23'] F1 score on Test 0.4746\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V24'] F1 score on Test 0.5424\n",
      "precision  0.6207 recall  0.6\n",
      "drop colnames ['V7', 'V25'] F1 score on Test 0.6102\n",
      "precision  0.6207 recall  0.6\n",
      "drop colnames ['V7', 'V26'] F1 score on Test 0.6102\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V27'] F1 score on Test 0.5424\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V7', 'V28'] F1 score on Test 0.5424\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V7', 'V29'] F1 score on Test 0.4746\n",
      "precision  0.5862 recall  0.5667\n",
      "drop colnames ['V7', 'V30'] F1 score on Test 0.5763\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V8', 'V1'] F1 score on Test 0.7458\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V2'] F1 score on Test 0.8475\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V8', 'V3'] F1 score on Test 0.5424\n",
      "precision  0.5517 recall  0.5333\n",
      "drop colnames ['V8', 'V4'] F1 score on Test 0.5424\n",
      "precision  0.7586 recall  0.7333\n",
      "drop colnames ['V8', 'V5'] F1 score on Test 0.7458\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V6'] F1 score on Test 0.8475\n",
      "precision  0.7241 recall  0.7\n",
      "drop colnames ['V8', 'V7'] F1 score on Test 0.7119\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V8'] F1 score on Test 0.8475\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V8', 'V9'] F1 score on Test 0.4746\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V8', 'V10'] F1 score on Test 0.4407\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V8', 'V11'] F1 score on Test 0.3729\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V8', 'V12'] F1 score on Test 0.1017\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V13'] F1 score on Test 0.8475\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V8', 'V14'] F1 score on Test 0.339\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V15'] F1 score on Test 0.8475\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V8', 'V16'] F1 score on Test 0.3729\n",
      "precision  0.0345 recall  0.0333\n",
      "drop colnames ['V8', 'V17'] F1 score on Test 0.0339\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V8', 'V18'] F1 score on Test 0.3729\n",
      "precision  0.6897 recall  0.6667\n",
      "drop colnames ['V8', 'V19'] F1 score on Test 0.678\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V20'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V21'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V22'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V23'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V24'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V25'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V26'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V27'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V28'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V29'] F1 score on Test 0.8475\n",
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V8', 'V30'] F1 score on Test 0.8475\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V1'] F1 score on Test 0.4068\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V2'] F1 score on Test 0.4068\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V3'] F1 score on Test 0.4407\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V4'] F1 score on Test 0.4407\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V5'] F1 score on Test 0.4407\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V6'] F1 score on Test 0.4407\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V7'] F1 score on Test 0.4068\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V8'] F1 score on Test 0.4746\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V9'] F1 score on Test 0.4746\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V10'] F1 score on Test 0.4068\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V9', 'V11'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V9', 'V12'] F1 score on Test 0.1017\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V13'] F1 score on Test 0.4746\n",
      "precision  0.1379 recall  0.1333\n",
      "drop colnames ['V9', 'V14'] F1 score on Test 0.1356\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V15'] F1 score on Test 0.4407\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V9', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V9', 'V17'] F1 score on Test 0.0678\n",
      "precision  0.3103 recall  0.3\n",
      "drop colnames ['V9', 'V18'] F1 score on Test 0.3051\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V9', 'V19'] F1 score on Test 0.4407\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V20'] F1 score on Test 0.4746\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V21'] F1 score on Test 0.4746\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V22'] F1 score on Test 0.4746\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V23'] F1 score on Test 0.4068\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V24'] F1 score on Test 0.4746\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V25'] F1 score on Test 0.4746\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V26'] F1 score on Test 0.4068\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V27'] F1 score on Test 0.4068\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V28'] F1 score on Test 0.4068\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V9', 'V29'] F1 score on Test 0.4068\n",
      "precision  0.4828 recall  0.4667\n",
      "drop colnames ['V9', 'V30'] F1 score on Test 0.4746\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V10', 'V1'] F1 score on Test 0.339\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V2'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V3'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V4'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V5'] F1 score on Test 0.3729\n",
      "precision  0.3103 recall  0.3\n",
      "drop colnames ['V10', 'V6'] F1 score on Test 0.3051\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V7'] F1 score on Test 0.3729\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V8'] F1 score on Test 0.4407\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V10', 'V9'] F1 score on Test 0.4068\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V10'] F1 score on Test 0.4407\n",
      "precision  0.1379 recall  0.1333\n",
      "drop colnames ['V10', 'V11'] F1 score on Test 0.1356\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V10', 'V12'] F1 score on Test 0.0678\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V13'] F1 score on Test 0.4407\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V10', 'V14'] F1 score on Test 0.0678\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V15'] F1 score on Test 0.4407\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V10', 'V16'] F1 score on Test 0.0678\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V10', 'V17'] F1 score on Test 0.0678\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V10', 'V18'] F1 score on Test 0.1695\n",
      "precision  0.2759 recall  0.2667\n",
      "drop colnames ['V10', 'V19'] F1 score on Test 0.2712\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V10', 'V20'] F1 score on Test 0.339\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V21'] F1 score on Test 0.4407\n",
      "precision  0.4483 recall  0.4333\n",
      "drop colnames ['V10', 'V22'] F1 score on Test 0.4407\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V23'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V24'] F1 score on Test 0.3729\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V10', 'V25'] F1 score on Test 0.4068\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V10', 'V26'] F1 score on Test 0.4068\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V10', 'V27'] F1 score on Test 0.339\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V10', 'V28'] F1 score on Test 0.3729\n",
      "precision  0.3448 recall  0.3333\n",
      "drop colnames ['V10', 'V29'] F1 score on Test 0.339\n",
      "precision  0.4138 recall  0.4\n",
      "drop colnames ['V10', 'V30'] F1 score on Test 0.4068\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V1'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V2'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V3'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V4'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V5'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V6'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V7'] F1 score on Test 0.1695\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V11', 'V8'] F1 score on Test 0.3729\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V11', 'V9'] F1 score on Test 0.1017\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V10'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.2069 recall  0.2\n",
      "drop colnames ['V11', 'V13'] F1 score on Test 0.2034\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V14'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V15'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V16'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V11', 'V17'] F1 score on Test 0.1017\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V18'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V19'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V20'] F1 score on Test 0.1695\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V11', 'V21'] F1 score on Test 0.3729\n",
      "precision  0.3793 recall  0.3667\n",
      "drop colnames ['V11', 'V22'] F1 score on Test 0.3729\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V23'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V24'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V25'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V26'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V27'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V28'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V29'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V11', 'V30'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V1'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V2'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V3'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V4'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V5'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V6'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V7'] F1 score on Test 0.1695\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V12', 'V8'] F1 score on Test 0.1017\n",
      "precision  0.1034 recall  0.1\n",
      "drop colnames ['V12', 'V9'] F1 score on Test 0.1017\n",
      "precision  0.069 recall  0.0667\n",
      "drop colnames ['V12', 'V10'] F1 score on Test 0.0678\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V11'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V12'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V13'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V14'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V15'] F1 score on Test 0.1695\n",
      "precision  0.1724 recall  0.1667\n",
      "drop colnames ['V12', 'V16'] F1 score on Test 0.1695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-14cfd549018b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mn_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mn_errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# override for transductive outlier detectors like LocalOulierFactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/covariance/_elliptic_envelope.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mNot\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mconsistency\u001b[0m \u001b[0mby\u001b[0m \u001b[0mconvention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    648\u001b[0m                           \"is not full rank\")\n\u001b[1;32m    649\u001b[0m         \u001b[0;31m# compute and store raw estimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         raw_location, raw_covariance, raw_support, raw_dist = fast_mcd(\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mcov_computation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nonrobust_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py\u001b[0m in \u001b[0;36mfast_mcd\u001b[0;34m(X, support_fraction, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples_merged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mlocations_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariances_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupports_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             select_candidates(\n\u001b[0m\u001b[1;32m    467\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_merged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_best_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_best_covariances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py\u001b[0m in \u001b[0;36mselect_candidates\u001b[0;34m(X, n_support, n_trials, select, n_iter, verbose, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0minitial_estimates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mestimates_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimates_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             all_estimates.append(_c_step(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_support\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0minitial_estimates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_estimates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py\u001b[0m in \u001b[0;36m_c_step\u001b[0;34m(X, n_support, random_state, remaining_iterations, initial_estimates, verbose, cov_computation_method)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_centered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# compute new estimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0msupport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_support\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mX_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \"\"\"\n\u001b[0;32m-> 1112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "delcols = []\n",
    "count = []\n",
    "f1s = []\n",
    "\n",
    "for col in colnames:\n",
    "    for col2 in colnames:\n",
    "        temp_list = [col,col2]\n",
    "        val_x2 = val_x.drop(columns=temp_list,axis=1)\n",
    "        cov = EllipticEnvelope(support_fraction = 0.994, contamination =0.001)\n",
    "        ground_truth = np.ones(len(val_x2), dtype=int)\n",
    "\n",
    "        y_pred = cov.fit_predict(val_x2)\n",
    "        n_errors = (y_pred != ground_truth).sum()\n",
    "        n_errors\n",
    "\n",
    "        y_predLOF = y_pred.copy()\n",
    "        y_predDF = pd.DataFrame(y_predLOF)\n",
    "        y_predDF[y_predDF[0] == 1] = 0\n",
    "        y_predDF[y_predDF[0] == -1] = 1\n",
    "\n",
    "        y_predLOF = y_predDF.values\n",
    "        y_predLOF = np.ravel(y_predLOF)\n",
    "\n",
    "        precision,recall,fbeta_score, support  = precision_recall_fscore_support(val_y, y_predLOF, average='binary') \n",
    "\n",
    "        print(\"precision \", round((precision), 4) ,\"recall \", round((recall), 4))\n",
    "        print(\"drop colnames\",temp_list, \"F1 score on Test\", round((fbeta_score), 4) )\n",
    "        \n",
    "        \n",
    "        delcols.append(temp_list)\n",
    "        f1s.append(round((fbeta_score), 4))\n",
    "        \n",
    "        # count.append(i*0.00001)\n",
    "\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delcols</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[V1, V1]</td>\n",
       "      <td>0.7458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[V1, V2]</td>\n",
       "      <td>0.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[V1, V3]</td>\n",
       "      <td>0.1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[V1, V4]</td>\n",
       "      <td>0.3390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[V1, V5]</td>\n",
       "      <td>0.6780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    delcols  f1_score\n",
       "0  [V1, V1]    0.7458\n",
       "1  [V1, V2]    0.4746\n",
       "2  [V1, V3]    0.1695\n",
       "3  [V1, V4]    0.3390\n",
       "4  [V1, V5]    0.6780"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'delcols':delcols,'f1_score':f1s})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delcol1'] = df.delcols.str[0]\n",
    "df['delcol2'] = df.delcols.str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delcol1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.667830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.557090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.548050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.473470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.472340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.449740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.381940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.325440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.319790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.186450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.154669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score\n",
       "delcol1          \n",
       "V8       0.667830\n",
       "V6       0.557090\n",
       "V2       0.548050\n",
       "V1       0.473470\n",
       "V7       0.472340\n",
       "V5       0.449740\n",
       "V9       0.381940\n",
       "V3       0.350300\n",
       "V10      0.325440\n",
       "V4       0.319790\n",
       "V11      0.186450\n",
       "V12      0.154669"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df2 =df.groupby('delcol1').mean()\n",
    "df2.sort_values('f1_score',inplace=True,ascending=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delcol2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.674918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.601725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>0.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>0.536236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>0.530073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.530073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.525450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.514664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>0.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>0.502336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.483845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.454825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.423750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>0.412964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.409625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.382145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.378550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.333350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.324875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.324875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.234475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.183625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.178745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.177975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.149725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.095536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score\n",
       "delcol2          \n",
       "V21      0.674918\n",
       "V22      0.644100\n",
       "V8       0.601725\n",
       "V13      0.576300\n",
       "V30      0.576300\n",
       "V24      0.536236\n",
       "V26      0.530073\n",
       "V20      0.530073\n",
       "V15      0.525450\n",
       "V25      0.514664\n",
       "V28      0.508500\n",
       "V27      0.502336\n",
       "V23      0.483845\n",
       "V6       0.474600\n",
       "V2       0.454825\n",
       "V7       0.440700\n",
       "V1       0.423750\n",
       "V29      0.412964\n",
       "V5       0.409625\n",
       "V19      0.382145\n",
       "V9       0.378550\n",
       "V10      0.333350\n",
       "V3       0.324875\n",
       "V4       0.324875\n",
       "V14      0.234475\n",
       "V16      0.183625\n",
       "V18      0.178745\n",
       "V11      0.177975\n",
       "V12      0.149725\n",
       "V17      0.095536"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 =df.groupby('delcol2').mean()\n",
    "df3.sort_values('f1_score',inplace=True,ascending=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision  0.8621 recall  0.8333\n",
      "drop colnames ['V21', 'V22', 'V8'] F1 score on Test 0.8475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_list = ['V21','V22','V8']\n",
    "val_x2 = val_x.drop(columns=temp_list,axis=1)\n",
    "cov = EllipticEnvelope(support_fraction = 0.994, contamination =0.001)\n",
    "ground_truth = np.ones(len(val_x2), dtype=int)\n",
    "\n",
    "y_pred = cov.fit_predict(val_x2)\n",
    "n_errors = (y_pred != ground_truth).sum()\n",
    "n_errors\n",
    "\n",
    "y_predLOF = y_pred.copy()\n",
    "y_predDF = pd.DataFrame(y_predLOF)\n",
    "y_predDF[y_predDF[0] == 1] = 0\n",
    "y_predDF[y_predDF[0] == -1] = 1\n",
    "\n",
    "y_predLOF = y_predDF.values\n",
    "y_predLOF = np.ravel(y_predLOF)\n",
    "\n",
    "precision,recall,fbeta_score, support  = precision_recall_fscore_support(val_y, y_predLOF, average='binary') \n",
    "\n",
    "print(\"precision \", round((precision), 4) ,\"recall \", round((recall), 4))\n",
    "print(\"drop colnames\",temp_list, \"F1 score on Test\", round((fbeta_score), 4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./Data/test.csv') # Train\n",
    "test_df.head()\n",
    "test_x = test_df.drop(columns=['ID'])\n",
    "\n",
    "cov = EllipticEnvelope(support_fraction = 0.994, contamination = 0.001)\n",
    "ground_truth = np.ones(len(test_x), dtype=int)\n",
    "\n",
    "y_pred = cov.fit_predict(test_x)\n",
    "\n",
    "y_predLOF = y_pred.copy()\n",
    "y_predDF = pd.DataFrame(y_predLOF)\n",
    "y_predDF[y_predDF[0] == 1] = 0\n",
    "y_predDF[y_predDF[0] == -1] = 1\n",
    "\n",
    "## Submission\n",
    "submit = pd.read_csv('./Data/sample_submission.csv')\n",
    "submit.head()\n",
    "submit['Class'] = y_predDF\n",
    "submit.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005,\n",
       " 0.006,\n",
       " 0.007,\n",
       " 0.008,\n",
       " 0.009000000000000001,\n",
       " 0.01,\n",
       " 0.011,\n",
       " 0.012,\n",
       " 0.013000000000000001,\n",
       " 0.014]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n",
      "0.973\n",
      "0.976\n",
      "0.979\n",
      "0.982\n",
      "0.985\n",
      "0.988\n",
      "0.991\n",
      "0.994\n"
     ]
    }
   ],
   "source": [
    "for i in range(970,997,3):\n",
    "    print(i*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision  0.8621\n",
      "recall  0.8333\n",
      "F1 score on Test 0.8475\n"
     ]
    }
   ],
   "source": [
    "cov = EllipticEnvelope(support_fraction = 0.994, contamination = 0.001)\n",
    "ground_truth = np.ones(len(val_x), dtype=int)\n",
    "\n",
    "y_pred = cov.fit_predict(val_x)\n",
    "n_errors = (y_pred != ground_truth).sum()\n",
    "n_errors\n",
    "\n",
    "y_predLOF = y_pred.copy()\n",
    "y_predDF = pd.DataFrame(y_predLOF)\n",
    "y_predDF[y_predDF[0] == 1] = 0\n",
    "y_predDF[y_predDF[0] == -1] = 1\n",
    "\n",
    "y_predLOF = y_predDF.values\n",
    "y_predLOF = np.ravel(y_predLOF)\n",
    "\n",
    "precision,recall,fbeta_score, support  = precision_recall_fscore_support(val_y, y_predLOF, average='binary')\n",
    "\n",
    "print(\"precision \", round((precision), 4))\n",
    "print(\"recall \", round((recall), 4))\n",
    "print(\"F1 score on Test\", round((fbeta_score), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "28457    0\n",
       "28458    0\n",
       "28459    0\n",
       "28460    0\n",
       "28461    0\n",
       "Name: Class, Length: 28462, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_xy = val_x.copy()\n",
    "\n",
    "val_xy['Class'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='V17'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x = 'Class', y='V17',data = val_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.14552438734553"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.V1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.38505</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>-0.255991</td>\n",
       "      <td>-0.994878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.145524</td>\n",
       "      <td>0.575068</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>2.598192</td>\n",
       "      <td>-0.092210</td>\n",
       "      <td>-1.044430</td>\n",
       "      <td>0.531588</td>\n",
       "      <td>-0.241888</td>\n",
       "      <td>-0.896287</td>\n",
       "      <td>0.757952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>-0.119703</td>\n",
       "      <td>-0.076510</td>\n",
       "      <td>0.69132</td>\n",
       "      <td>0.633984</td>\n",
       "      <td>0.048741</td>\n",
       "      <td>-0.053192</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.169496</td>\n",
       "      <td>-0.994502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "2  1.145524  0.575068  0.194008  2.598192 -0.092210 -1.044430  0.531588   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23      V24  \\\n",
       "0  0.069539 -0.736727 -0.366846  ... -0.246914 -0.633753 -0.120794 -0.38505   \n",
       "2 -0.241888 -0.896287  0.757952  ...  0.011106 -0.119703 -0.076510  0.69132   \n",
       "\n",
       "        V25       V26       V27       V28       V29       V30  \n",
       "0 -0.069733  0.094199  0.246219  0.083076 -0.255991 -0.994878  \n",
       "2  0.633984  0.048741 -0.053192  0.016251  0.169496 -0.994502  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x[(val_x.V1 == -0.33826175242575 )|(val_x.V1 == 1.14552438734553)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cd8ab235991ec21a8c18909a3ffb6c6aa655e4cacee6331ca5c07df8f3aac09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
