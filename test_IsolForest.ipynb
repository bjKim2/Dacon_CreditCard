{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./Data/train.csv') # Train\n",
    "train_df = train_df.drop(columns=['ID']) \n",
    "val_df = pd.read_csv('./Data/val.csv') # Validation\n",
    "\n",
    "val_normal, val_fraud = val_df['Class'].value_counts()\n",
    "val_contamination = val_fraud / val_normal\n",
    "\n",
    "train_x = train_df.copy()\n",
    "\n",
    "def get_pred_label(model_pred):\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred\n",
    "\n",
    "val_x = val_df.drop(columns=['ID', 'Class']) # Input Data\n",
    "val_y = val_df['Class'] # Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def df_normal(norm_df):\n",
    "    col = list(norm_df.columns[:])\n",
    "    x = norm_df[col].values\n",
    "    #최대값과 최소값의 값 가져오기\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler\n",
    "    # 정규화 시킬 최종 값은 비율로 계산되기 때문에 float설정\n",
    "    x_scaled = min_max_scaler.fit_transform(x.astype(float))\n",
    "    x_scaled\n",
    "\n",
    "    norm_df_norm = pd.DataFrame(x_scaled, columns=col, index=norm_df.index)\n",
    "    return norm_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_norm = df_normal(train_df)\n",
    "val_x_norm = df_normal(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_norm.to_csv(\"./norm_Data/train_norm.csv\",index=False)\n",
    "val_x_norm.to_csv(\"./norm_Data/val_x_norm.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>0.907349</td>\n",
       "      <td>0.725133</td>\n",
       "      <td>0.868055</td>\n",
       "      <td>0.348965</td>\n",
       "      <td>0.481234</td>\n",
       "      <td>0.551452</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>0.685828</td>\n",
       "      <td>0.480640</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388826</td>\n",
       "      <td>0.637336</td>\n",
       "      <td>0.568382</td>\n",
       "      <td>0.438913</td>\n",
       "      <td>0.523647</td>\n",
       "      <td>0.257375</td>\n",
       "      <td>0.545613</td>\n",
       "      <td>0.354415</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.999826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>0.900517</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.850779</td>\n",
       "      <td>0.270710</td>\n",
       "      <td>0.489491</td>\n",
       "      <td>0.544557</td>\n",
       "      <td>0.556383</td>\n",
       "      <td>0.689571</td>\n",
       "      <td>0.501823</td>\n",
       "      <td>0.609683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382689</td>\n",
       "      <td>0.554674</td>\n",
       "      <td>0.575542</td>\n",
       "      <td>0.525004</td>\n",
       "      <td>0.504670</td>\n",
       "      <td>0.399586</td>\n",
       "      <td>0.521043</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.999861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>0.910463</td>\n",
       "      <td>0.722728</td>\n",
       "      <td>0.872260</td>\n",
       "      <td>0.352196</td>\n",
       "      <td>0.482466</td>\n",
       "      <td>0.550039</td>\n",
       "      <td>0.564999</td>\n",
       "      <td>0.651923</td>\n",
       "      <td>0.519854</td>\n",
       "      <td>0.648162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405864</td>\n",
       "      <td>0.605004</td>\n",
       "      <td>0.568999</td>\n",
       "      <td>0.428226</td>\n",
       "      <td>0.522940</td>\n",
       "      <td>0.264520</td>\n",
       "      <td>0.556500</td>\n",
       "      <td>0.356753</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.999896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>0.988342</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>0.842372</td>\n",
       "      <td>0.308731</td>\n",
       "      <td>0.469669</td>\n",
       "      <td>0.545766</td>\n",
       "      <td>0.543473</td>\n",
       "      <td>0.675804</td>\n",
       "      <td>0.568850</td>\n",
       "      <td>0.653727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375270</td>\n",
       "      <td>0.535192</td>\n",
       "      <td>0.579067</td>\n",
       "      <td>0.378578</td>\n",
       "      <td>0.494755</td>\n",
       "      <td>0.385389</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.344093</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28461</th>\n",
       "      <td>0.916931</td>\n",
       "      <td>0.708646</td>\n",
       "      <td>0.897580</td>\n",
       "      <td>0.335219</td>\n",
       "      <td>0.461629</td>\n",
       "      <td>0.593477</td>\n",
       "      <td>0.531229</td>\n",
       "      <td>0.696403</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.634312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389839</td>\n",
       "      <td>0.638785</td>\n",
       "      <td>0.568656</td>\n",
       "      <td>0.453265</td>\n",
       "      <td>0.472822</td>\n",
       "      <td>0.459472</td>\n",
       "      <td>0.535191</td>\n",
       "      <td>0.351548</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "28457  0.907349  0.725133  0.868055  0.348965  0.481234  0.551452  0.561737   \n",
       "28458  0.900517  0.709703  0.850779  0.270710  0.489491  0.544557  0.556383   \n",
       "28459  0.910463  0.722728  0.872260  0.352196  0.482466  0.550039  0.564999   \n",
       "28460  0.988342  0.695769  0.842372  0.308731  0.469669  0.545766  0.543473   \n",
       "28461  0.916931  0.708646  0.897580  0.335219  0.461629  0.593477  0.531229   \n",
       "\n",
       "             V8        V9       V10  ...       V21       V22       V23  \\\n",
       "28457  0.685828  0.480640  0.643668  ...  0.388826  0.637336  0.568382   \n",
       "28458  0.689571  0.501823  0.609683  ...  0.382689  0.554674  0.575542   \n",
       "28459  0.651923  0.519854  0.648162  ...  0.405864  0.605004  0.568999   \n",
       "28460  0.675804  0.568850  0.653727  ...  0.375270  0.535192  0.579067   \n",
       "28461  0.696403  0.566360  0.634312  ...  0.389839  0.638785  0.568656   \n",
       "\n",
       "            V24       V25       V26       V27       V28       V29       V30  \n",
       "28457  0.438913  0.523647  0.257375  0.545613  0.354415  0.003069  0.999826  \n",
       "28458  0.525004  0.504670  0.399586  0.521043  0.344500  0.006724  0.999861  \n",
       "28459  0.428226  0.522940  0.264520  0.556500  0.356753  0.005085  0.999896  \n",
       "28460  0.378578  0.494755  0.385389  0.524941  0.344093  0.000225  0.999977  \n",
       "28461  0.453265  0.472822  0.459472  0.535191  0.351548  0.000840  1.000000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x_norm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.6061198984211713]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.13      0.63      0.21        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.56      0.81      0.61     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정규화된 데이터 테스트\n",
    "\n",
    "collist01 = ['V3','V9','V11','V12','V16','V17']\n",
    "train_x_norm =train_df_norm.loc[:,collist01]\n",
    "model = IsolationForest(n_estimators=50, max_samples=len(train_x_norm), contamination=0.00105, random_state=42, verbose=0)\n",
    "model.fit(train_x_norm)\n",
    "## Evaluation : Validation set\n",
    "def get_pred_label(model_pred):\n",
    "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred\n",
    "val_x_norm2 = val_x_norm.loc[:,collist01]\n",
    "val_y = val_df['Class'] # Label\n",
    "\n",
    "val_pred = model.predict(val_x_norm2) # model prediction\n",
    "val_pred = get_pred_label(val_pred)\n",
    "val_score = f1_score(val_y, val_pred, average='macro')\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(val_y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.7928924258723169]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.61      0.57      0.59        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.80      0.78      0.79     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 일반 데이터 데스트\n",
    "collist01 = ['V3','V9','V11','V12','V16']\n",
    "train_x =train_df.loc[:,collist01]\n",
    "model = IsolationForest(n_estimators=30, max_samples=len(train_x), contamination=0.00105, random_state=42, verbose=0)\n",
    "model.fit(train_x)\n",
    "## Evaluation : Validation set\n",
    "def get_pred_label(model_pred):\n",
    "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred\n",
    "val_x = val_df.loc[:,collist01]\n",
    "val_y = val_df['Class'] # Label\n",
    "\n",
    "val_pred = model.predict(val_x) # model prediction\n",
    "val_pred = get_pred_label(val_pred)\n",
    "val_score = f1_score(val_y, val_pred, average='macro')\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(val_y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 30 features, but IsolationForest is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/fgx0kt2j66zf6nrrj6v3_t9w0000gn/T/ipykernel_43201/4128589697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## Submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m    339\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mdecision_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mis_inlier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mis_inlier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecision_func\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# an outlier:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mscore_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Take the opposite of the scores as bigger is better (here less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 30 features, but IsolationForest is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "#제출용\n",
    "test_df = pd.read_csv('./Data/test.csv') # Train\n",
    "test_df.head()\n",
    "test_x = test_df.drop(columns=['ID'])\n",
    "test_pred = model.predict(test_x) # model prediction\n",
    "test_pred = get_pred_label(test_pred)\n",
    "## Submission\n",
    "submit = pd.read_csv('../Data/sample_submission.csv')\n",
    "submit.head()\n",
    "submit['Class'] = test_pred\n",
    "submit.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cd8ab235991ec21a8c18909a3ffb6c6aa655e4cacee6331ca5c07df8f3aac09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
